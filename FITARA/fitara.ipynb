{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LABELS = 'participants/train/labels/labels.csv'\n",
    "TRAIN_TEXT = 'participants/train/extracted_data/extract_combined.csv'\n",
    "TEST_TEXT = 'participants/test/extracted_data/extract_combined.csv'\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_labels_df = pd.read_csv(TRAIN_LABELS, usecols=['document_name','is_fitara'])\n",
    "train_text_df = pd.read_csv(TRAIN_TEXT)\n",
    "test_df = pd.read_csv(TEST_TEXT)\n",
    "\n",
    "msk = np.random.rand(train_text_df.shape[0]) < 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_y = pd.get_dummies(train_labels_df.is_fitara.values)\n",
    "# train_labels_df_OHE['Yes'] = train_y.Yes\n",
    "# train_labels_df_OHE = train_labels_df_OHE.drop(['is_fitara'], axis = 1)\n",
    "# train_labels_df_OHE = train_labels_df.copy()\n",
    "train_labels_df.is_fitara = train_labels_df.is_fitara.eq('Yes').mul(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_name</th>\n",
       "      <th>is_fitara</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04-42RFP.pdf</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n \\nOMB No. 0990-0115  \\n \\n Electronic Requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_-_Brand_name_JOFOC_1782798.pdf</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n \\nJustification for Other than Full and Op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_-_Brand_Name_JOFOC_for_FBO.docx</td>\n",
       "      <td>0</td>\n",
       "      <td>Justification for Other than Full and Open Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_-_Brand_Name_Only.docx</td>\n",
       "      <td>1</td>\n",
       "      <td>Justification for Other than Full and Open Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_-_JOFOC_-_FSSI_Limited_Source.doc</td>\n",
       "      <td>1</td>\n",
       "      <td>Attachment C\\r\\r\\rHHS Template and Instruction...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         document_name  is_fitara  \\\n",
       "0                         04-42RFP.pdf          0   \n",
       "1     1_-_Brand_name_JOFOC_1782798.pdf          0   \n",
       "2    1_-_Brand_Name_JOFOC_for_FBO.docx          0   \n",
       "3             1_-_Brand_Name_Only.docx          1   \n",
       "4  1_-_JOFOC_-_FSSI_Limited_Source.doc          1   \n",
       "\n",
       "                                                text  \n",
       "0   \\n \\nOMB No. 0990-0115  \\n \\n Electronic Requ...  \n",
       "1   \\n \\nJustification for Other than Full and Op...  \n",
       "2  Justification for Other than Full and Open Com...  \n",
       "3  Justification for Other than Full and Open Com...  \n",
       "4  Attachment C\\r\\r\\rHHS Template and Instruction...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine labels with text features\n",
    "train_df = pd.merge(\n",
    "    train_labels_df, \n",
    "    train_text_df, \n",
    "    on='document_name', \n",
    "    how='inner'\n",
    ")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_XY = train_df[msk]\n",
    "test_XY = train_df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGram TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data,  TFIDF, Count with MultinoialNB"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(train_XY.text.values)\n",
    "tfidf_test = tfidf_vectorizer.transform(test_XY.text.values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(train_XY.text.values)\n",
    "count_test = count_vectorizer.transform(test_XY.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(train_XY.text)\n",
    "ngram_train = tfidf_vect_ngram.transform(train_XY.text.values)\n",
    "ngram_test = tfidf_vect_ngram.transform(test_XY.text.values)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(tfidf_train, train_XY.is_fitara)\n",
    "tfidf_pred = nb_classifier.predict(tfidf_test)\n",
    "tfidf_score = metrics.accuracy_score(test_XY.is_fitara, tfidf_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('============= TFIDF VECTORIZER ================')\n",
    "print('Loss = ',metrics.log_loss(test_XY.is_fitara, tfidf_pred))\n",
    "print('Score = ',tfidf_score)\n",
    "print('CM = \\n',metrics.confusion_matrix(test_XY.is_fitara, tfidf_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nb_classifier1 = MultinomialNB()\n",
    "nb_classifier1.fit(count_train, train_XY.is_fitara)\n",
    "count_pred = nb_classifier1.predict(count_test)\n",
    "count_score = metrics.accuracy_score(test_XY.is_fitara, count_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print('============= COUNT VECTORIZER ================')\n",
    "print('Loss = ',metrics.log_loss(test_XY.is_fitara, count_pred))\n",
    "print('Score = ',count_score)\n",
    "print('CM = \\n',metrics.confusion_matrix(test_XY.is_fitara, count_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier2 = MultinomialNB()\n",
    "nb_classifier2.fit(ngram_train, train_XY.is_fitara)\n",
    "ngram_pred = nb_classifier2.predict(ngram_test)\n",
    "ngram_score = metrics.accuracy_score(test_XY.is_fitara, ngram_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= NGRAM VECTORIZER ================\n",
      "Loss =  6.60644513180034\n",
      "Score =  0.8087248322147651\n",
      "CM = \n",
      " [[199  13]\n",
      " [ 44  42]]\n"
     ]
    }
   ],
   "source": [
    "print('============= NGRAM VECTORIZER ================')\n",
    "print('Loss = ',metrics.log_loss(test_XY.is_fitara, ngram_pred))\n",
    "print('Score = ',ngram_score)\n",
    "print('CM = \\n',metrics.confusion_matrix(test_XY.is_fitara, ngram_pred, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_pred_prob = nb_classifier2.predict_proba(ngram_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for (indx, prob) in enumerate(ngram_pred_prob):\n",
    "    print(indx, round(prob[0], 4) , round(prob[1],4), ngram_pred[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_validate = tfidf_vect_ngram.transform(test_df.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_validate_pred = nb_classifier2.predict_proba(ngram_validate)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i, pred1 in enumerate(ngram_validate_pred):\n",
    "    print(test_df.document_name.values[i] , round(pred1[1],4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame()\n",
    "predictions_df['document_name'] = test_df.document_name\n",
    "predictions_df['pred_fitara'] = np.round(ngram_validate_pred[:,1], decimals= 4)\n",
    "# predictions_df.to_csv('participants/predictions.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_df.to_csv('participants/predictions.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
